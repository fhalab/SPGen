{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from transformer import Models\n",
    "from transformer import Beam\n",
    "from transformer import Translator\n",
    "from transformer.Optim import ScheduledOptim\n",
    "\n",
    "from tools import CharacterTable\n",
    "from translator import SignalTranslator\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "with open('../outputs/ctable_token.pkl', 'rb') as f:\n",
    "    ctable = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for tokenizing new inputs\n",
    "alphabet = ' .$ACDEFGHIKLMNPQRSTUVWXYZ'\n",
    "max_len_in = 107 # max length of prot seq (105 aa) + 2 for tokens\n",
    "max_len_out = 72\n",
    "n_chars = len(alphabet)\n",
    "\n",
    "with open('../data/ctable_copies/ctable_token_master.pkl', 'rb') as f:\n",
    "    ctable = pickle.load(f)\n",
    "\n",
    "def encode(seqs, max_len, ctable):\n",
    "    if ctable.one_hot:\n",
    "        X = np.zeros((len(seqs), max_len, n_chars))\n",
    "    else:\n",
    "        X = np.zeros((len(seqs), max_len))\n",
    "    seqs = ['$' + seq + '.' for seq in seqs]\n",
    "    seqs = [seq + ' ' * ((max_len) - len(seq))for seq in seqs]\n",
    "    for i, seq in enumerate(seqs):\n",
    "        X[i] = ctable.encode(seq, max_len)\n",
    "    return X\n",
    "\n",
    "def to_h5py(seqs, fname, ctable):\n",
    "    chunksize = 500\n",
    "    with h5py.File(fname, 'w') as f:\n",
    "        if ctable.one_hot:\n",
    "            print('true')\n",
    "            X = f.create_dataset('X', (len(seqs), max_len_in, n_chars))\n",
    "        else:\n",
    "            X = f.create_dataset('X', (len(seqs), max_len_in))          \n",
    "        for i in range(0, len(seqs), chunksize):\n",
    "            X[i:i + chunksize, :] = encode([seq for seq in seqs[i:i+chunksize]], max_len_in, ctable)\n",
    "        left = len(seqs) % chunksize\n",
    "        if left > 0:\n",
    "            X[-left:, :] = encode([seq for seq in seqs[-left:]], max_len_in, ctable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample input, convert to h5py file for generator\n",
    "df = pd.read_excel('../data/example_test_input.xlsx')\n",
    "test_seqs = df['protein_sequence'].values\n",
    "test_seqs = [s[:100] for s in test_seqs]\n",
    "test_filename = ('../data/example_test_tokens.hdf5')\n",
    "to_h5py(test_seqs, test_filename, ctable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(cuda=True, d_inner_hid=1100, d_k=64, d_model=550, d_v=64, d_word_vec=550, dropout=0.1, embs_share_weight=True, max_token_seq_len=107, n_head=5, n_layers=6, proj_share_weight=True, src_vocab_size=27, tgt_vocab_size=27) Namespace(beam_size=1, ctable=<tools.CharacterTable object at 0x7f9f164671d0>, max_trans_length=72, n_best=1) Namespace(d_model=None, decay_power=-0.03, lr_max=0.0001, n_warmup_steps=12500, optim=<class 'torch.optim.adam.Adam'>)\n",
      "position_encoding\n",
      "position_encoding\n",
      "Initiated Transformer with 27403200 parameters.\n"
     ]
    }
   ],
   "source": [
    "# Load a Model Checkpoint\n",
    "chkpt_name = 'SIM99_550_12500_64_6_5_0.1_64_100_0.0001_-0.03_99'\n",
    "chkpt = \"../outputs/models/model_checkpoints/\" + chkpt_name + \".chkpt\"\n",
    "clf = SignalTranslator.load_model(chkpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py:357: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  result = self.forward(*input, **kwargs)\n",
      "/home/ubuntu/signal_peptide_review/code/translator.py:376: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = self.model.prob_projection(dec_output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MKKPLGKIVASTALLISVAFSSSIASA.\n",
      "\n",
      "MIKKIPLKTIAVMALSGCTFFVNG.\n",
      "\n",
      "MRLAKIAGLTASLLFSLWGALA.\n",
      "\n",
      "MAILVLLFLLAVEINS.\n",
      "\n",
      "MKMRTGKKGFLSILLAFLLVITSIPFTLVDVEA.\n",
      "\n",
      "MKLFTATIAVLGAVSATAHA.\n",
      "\n",
      "MKDLFRLIALLSCCLALFPLTFA.\n",
      "\n",
      "MKSLLLTAFAAGTALA.                                                       \n",
      "\n",
      "MNKLFYLFMLGLAAFA.                                                       \n",
      "\n",
      "MKLKIVFAVAAIAPVLHS.\n",
      "\n",
      "MKFTQAVLSLLGSAATALA.\n",
      "\n",
      "MNIRLGALLAGLLLSAMASAVFA.\n",
      "\n",
      "MKKSLISFLALGLLFGSAFA.\n",
      "\n",
      "MKFLSIVLLIVGLAYG.\n",
      "\n",
      "MFKFVLVLSVLAALASARA.\n",
      "\n",
      "MLTFHRIIRKGWMFLLAFLLTALLFCPTGQPAKA.\n",
      "\n",
      "MNLKILFALALGVCLAA.\n",
      "\n",
      "MVSNKRVLALSALFGCCSLASA.\n",
      "\n",
      "MKNFATLSAVLAGATALA.                                                     \n",
      "\n",
      "MIRLKRLLAGLLLPLFVTAFG.\n",
      "\n",
      "MKKTGFIGKTLALVIAAGMAGTAAFA.\n",
      "\n",
      "MKKTILALALLGSLAA.                                                       \n",
      "\n",
      "MTLKTTITLFFAALSANAAFA.\n",
      "\n",
      "MKFQDLTLVLSLSTALA.\n",
      "\n",
      "MKLLTSFVLIGALAFA.                                                       \n",
      "\n",
      "MGIQKKVSILVAGLFMATAFATA.\n",
      "\n",
      "MKKTAAIAALAGLSFAGMAHA.\n",
      "\n",
      "MVASLWSSILPVLAFLWADLSAGA.\n",
      "\n",
      "MKKRLLIASVALGSLFSFCA.\n",
      "\n",
      "MARA.\n",
      "\n",
      "MKFLILLITLGAIAATALA.\n",
      "\n",
      "MKLFKILTACLFIGLLNVSA.\n",
      "\n",
      "MKLSQSLTYLAVLGLAAGANA.\n",
      "\n",
      "MRSLLLTLLGALLRA.                                                        \n",
      "\n",
      "MKFLIPLFVLFIVFGNAYA.                                                    \n",
      "\n",
      "MKKRVISALAALWLSVLGAPAVLA.\n",
      "\n",
      "MTQKSLLLALTAVALVSVNA.\n",
      "\n",
      "MKGTLAFLLVFLLNLYVHG.\n",
      "\n",
      "MKCCRIMFVLLGLWFVFGLSVPGGRTEA.\n",
      "\n",
      "MKLLKVIATAFLGLTSFASA.\n",
      "\n",
      "MRSLLLTSALAALVSLAAASA.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test_gen_data = []\n",
    "# Generate SPs for Proteins\n",
    "file = h5py.File(test_filename)\n",
    "training_data = SignalTranslator.generator_from_h5_noy(file, 64, shuffle=False, use_cuda=True)\n",
    "src = next(training_data) # src is prot sequence, tgt is signal pep\n",
    "file.close()\n",
    "clf_outputs  = clf.translate_batch(src, 5)\n",
    "decoded, all_hyp, all_scores, enc_outputs, dec_outputs, enc_slf_attns, dec_slf_attns, dec_enc_attn = clf_outputs\n",
    "\n",
    "for src, dec in zip(src[0], decoded):\n",
    "#     print(ctable.decode(src.data.cpu().numpy())[:]) # prot sequence from Zach's excel\n",
    "    print(dec) # model's predictions\n",
    "    print()\n",
    "    \n",
    "    input_seq = ctable.decode(src.data.cpu().numpy())[:]\n",
    "    output_seq = dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
